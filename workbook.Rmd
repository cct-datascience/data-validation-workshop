---
title: "Data Validation in Excel and R"
author: "Eric R. Scott"
date: '2022-08-24'
---

# Load packages

```{r}
library(tidyverse)
library(visdat)
library(pointblank)
library(readxl)
library(skimr)
```

# Learning Objectives

-   Understand best practices for entering data and fixing errors in data
-   Use Excel data validation tools to prevent data entry errors
-   Compare data entered by two people in R to check for data entry mistakes
-   Explore data summaries to check for errors
-   Get the gist of how you can use the `pointblank` package to perform data validation checks


# Data Validation Tools in Excel

-   Select a column (or cells) and choose `Data > Validation â€¦` from the menu
-   Use "list" to restrict to specific values for categorical data
-   Use "whole number" for count data
-   Use "date" to restrict date ranges

To stop Excel from converting entries to dates:

1.  Explicitly set all column types to numeric, text, date, etc.
2.  Make sure no columns are set to "general"

# Double-entry Method

-   Two people enter the same data, then compare programatically.
-   In the `data` folder, there are two versions of a dataset---one entered by Eric and one entered by Jessica.

```{r}
eric <- read_csv("data/tea_eric.csv")
jessica <- read_csv("data/tea_jessica.csv")
```

## Compare visually with `visdat`

We can compare them a couple of ways.
First, we can compare them visually using the `visdat` package.
This only works if the two datasets are the same dimensions.

```{r}
vis_compare(eric, jessica)
```

## Compare with `dplyr::anti_join()`

First add row numbers to make it easier to find mistakes in Excel.

```{r}
# Optional: add rownumbers that match Excel (headers are row 1)
eric    <- eric    %>% mutate(row = 2:(n()+1), .before = date)
jessica <- jessica %>% mutate(row = 2:(n()+1), .before = date)
```

`anti_join()` takes two data frames and returns only rows that differ between them.

```{r}
#values in `eric` that are different in `jessica`
anti_join(eric, jessica)
#values in `jessica` that are different in `eric`
anti_join(jessica, eric)
```

What errors can you spot?


If this were a real example, you'd need to go back to your raw data sheets to figure out what went wrong.  We'll skip that part and just read in "tea_resolved.csv" for the rest of the workshop.

```{r}
#after fixing data-entry errors, we get `data_resolved.csv`
tea <- read_csv("data/tea_resolved.csv")
```

# Explore data summaries

-   You can't check for errors if you don't get to know your data!
-   Use `skimr::skim()` to get a nicely formatted summary
-   Look for number of unique values for categorical variables
-   Look for long tails or strange patterns in mini-histograms for numeric variables

```{r}
skimr::skim(tea)
```

Or get a more detailed breakdown by running `skim()` on a grouped data frame:

```{r}
#hint: use `group_by()` before passing data to `skim()`
```

## Explore data visually

-   `visdat::vis_guess()` can help spot inconsistencies

```{r}
visdat::vis_guess(tea)
```

Try intentionally introducing different kinds of mistakes to see if `vis_guess()` can spot them:

- change a `plant_id` to a character value
- change a `plot` to a number
- change a value of `hoppers` to a decimal

```{r}
tea_messed_up <- tea

# mess up the data.  E.g. this changes the 25th value of `plant_id`:
tea_messed_up$plant_id[25] <- "plant1"




vis_guess(tea_messed_up)
```


# Data validation pipelines with `pointblank`

https://rich-iannone.github.io/pointblank

```{r}
library(pointblank)
```


## `pointblank` demo

1.  Decide on "action levels". Can set a number or fraction of rows as a threshold for a warning or error

```{r}
al <- action_levels(warn_at = 1, stop_at = .05)
al
```

2.  Create agent

```{r}
agent <- 
  create_agent(
    tbl = tea, #our data example from before
    actions = al
  )
```

3.  Specify validation conditions

    -   Basic checks on column types with `col_is_*()` functions
    -   Check column values with `col_vals_*()` functions
    -   Check rows (e.g. duplicate rows) with `rows_*()` functions

```{r}
agent_informed <- 
  agent %>% 
  col_is_date(date) %>% # should be a date
  col_vals_in_set(field, c("A", "B")) %>%
  # all shoot_ columns should be less than 15 cm (NAs allowed)
  col_vals_lt(starts_with("shoot_"), 15, na_pass = TRUE)
  

```

4.  Interrogate!

```{r}
agent_informed %>% interrogate()
```

## Add validation steps

Try using `col_is*()`, `col_vals*()`, and `rows_*()` functions to add the following validation steps:

  - check that the `hoppers`, `shts_*`, and `leaves` columns are numeric
  - check that `counter` should be "W", "G", or "E" only (use `col_vals_in_set()`)
  - check that `plant_id` should be in 1:20 (use `col_vals_between()`)
  - check that there are no missing values for `date`, `field`, `time`, and `plant_id` (use `col_vals_not_null()`)


## Flexible validations

If a validation function you need doesn't exist, you can use `col_vals_expr()`

This uses the modulo operator `%%` to check if `hoppers` is an integer.

```{r}
agent_informed  %>%  
  col_vals_expr(~ hoppers %% 1 == 0) %>%  #modulo operation (%%) returns remainder
  interrogate()
```

Try adding a validation step to check that values in the `leaves` column are integers.

```{r}
agent_informed %>% 
  #add your validation steps
  interrogate()
```

## Create new columns to test on the fly

"preconditions" let you manipulate the data before a check is run within a single validation step.

Let's say we wanted to check that the density of leafhoppers was less than 0.5 (a reasonable expectation based on experience in the field).  To calculate density with `dplyr`:

```{r}
tea %>% 
  mutate(density = hoppers / leaves)
```

We can put this *inside* a validation step as a "precondition"

```{r}
agent_informed %>% 
  col_vals_lt(
    columns = density, #doesn't exist yet 
    value = 0.5, #expect less than 0.5
    na_pass = TRUE, #allow NAs
    # creates a new column on the fly:
    preconditions = function(df) df %>% mutate(density = hoppers / leaves)
    ) %>% 
  interrogate()
```

The precondition can be any kind of manipulation, even creating a summary table!  We could check that the standard deviation of `hoppers` for each plant over the whole time period is under some threshold value.

`dplyr` code:

```{r}
tea %>% 
  group_by(field, plant_id) %>% 
  summarize(hopper_sd = sd(hoppers, na.rm = TRUE))
```

Challenge problem: try turning that into a precondition in this validation step:

```{r}
agent_informed %>% 
  col_vals_lt(
    columns = hopper_sd,
    value = 2,
    preconditions = # your code here
    ) %>% 
  interrogate()
```

